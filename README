## ğŸ›³ï¸ Titanic Survival Prediction (Machine Learning Project)
## ğŸ“˜ Overview

This project predicts whether a passenger survived the Titanic disaster using machine learning.
We use multiple models â€” Random Forest, XGBoost, and Gradient Boosting â€” along with preprocessing pipelines and GridSearchCV to tune hyperparameters and improve accuracy.

---

## ğŸ§© Dataset
```
Train dataset: train.csv
Test dataset: test.csv
Target column: Survived
ID column: PassengerId
```
You can get the dataset from Kaggle - Titanic: Machine Learning from Disaster.

---

## âš™ï¸ Feature Engineering
```
Different feature engineering techniques used:
Handle missing values in Age, Fare, and Embarked.
Extract Title from Name (e.g., Mr, Miss, Mrs, etc.).
Convert Sex to numeric (0 = male, 1 = female).
Create FamilySize = SibSp + Parch + 1.
Create IsAlone (1 if traveling alone, 0 otherwise).
Convert categorical variables (Embarked, Title) using OneHotEncoder.
Scale numerical features using StandardScaler.
```

---

## ğŸ§  Models Used
```
RandomForestClassifier
XGBClassifier
GradientBoostingClassifier
Each model is wrapped in a Pipeline with preprocessing steps.
```

---

## ğŸ” Hyperparameter Tuning (GridSearchCV)
## ğŸ“Š Model Comparison
```
A comparison graph is plotted to visualize accuracy for:
Random Forest
XGBoost
Gradient Boosting
```
---

ğŸ§° Tools & Libraries
```
Python
Pandas, NumPy
Scikit-learn
XGBoost
RandomForestClassifier
GradientBoostingClassifier
Matplotlib + Seaborn

---

## Clone the repo
git clone https://github.com/Ydv-Suman/Titanic_Survival_Prediction.git
cd Titanic_Survival_Prediction
